Deep learning is a part of machine learning domain. Computational model of deep learning is composed of multiple layers to learn the representation of data. Each layer extracts the representation of input data which comes from the previous layers, then it will compute a new presentation for the next layer. In a deep learning model, each layer may contain different number of nodes, called \textit{neurons} which have been inspired from the biological neural system. Actually, the computation at each layer is made by own neurons, and the operation at each neuron is also the same as a biological neural: the neuron receives different pieces of information and function properties to give the decision. Currently, deep learning has many kind of variant architectures such as Deep Neural Network (DNN), Convolutional Neural Network (CNN) or Recurrent Neural Network (RNN), which have been applied to different fields including computer vision, speech recognition, natural language processing, machine translation, \ldots, and each variant architecture has found success in a specific domain, i.e. DNN can be applied to solve the classification or data analysis, RNN give the best perform on language modeling, while CNN is widely applied in computer vision.

In the architectures of deep learning, CNN is a specific network for pre-processing data which have grid topology, i.e. time series (1-D) or images (2D). The name of the network is inspired by the convolution operation which is a kind of linear operation. A CNN consists of an input, an output layer, as well as one or multiple hidden layers. It has also the score function and the loss function at the end of the model. The computing of CNN affects on $3$ dimensions of data: width, height, and depth. An input after being put on the network will be passed through a series of hidden layers before giving the outputs at the last layer. In a CNN, the hidden layers typically consist of convolutional layers, pooling layers, fully connected layer, \ldots. From the first architecture \cite{lecun1998gradient} until now, many CNN architectures have been proposed and have succeeded in different tasks of computer vision such as image classification \cite{lecun1998gradient, krizhevsky2012imagenet,szegedy2015going}, object recognition \cite{szegedy2015going,farabet2013learning,li2015convolutional}.

In computer vision, key points detection is an important field in image analysis. In this field, the algorithms try to find the key points (called interest points or landmarks) in the image. The landmarks are considered as the points in the image that are invariant when the image change i.e. by rotating or translating. Depending on the object, the number of landmarks may be different, as well as their position can be defined along the outline of the object or inside the object such as the landmarks on Drosophila wing \cite{palaniswamy2010automatic} are stayed on the veins of the wings, but the landmarks on human ears \cite{cintas2016automatic} can be located on the ear edge or inside the Pimas of the ears. The detected key points are then used in different objectives of different domains, for example, they are used to recognize the seabed in geosciences; in computer vision, they are fundamental to detect the human face or human pose; in biology, the topography of the objects of an organism can be measured from the location of landmarks.
 
%Key points detection has a wide use and becomes a critical in image analysis of different domains, such as: In geosciences, the key points can be used to recognize the seabed by extracting and comparing the landmarks from sonar images at different times; or computer vision, they are fundamental to detect the human face or human pose; in biology, the topography of the objects of an organism can be measured if we have enough the number of landmarks. Landmarks, or \textit{key points}, or \textit{points of interest}, are the points on the image that store important information about the shape of the object, \textit{for example}, the left and right corners of eyes are two important points to detect the human eyes. Depending on the object, the number of landmarks may  be different, as well as their position can be defined along the outline of the object or inside the object, i.e. the landmarks on Drosophila wings \cite{drosophilaWings} are stayed on the veins of the wings, but the landmarks on human ears \cite{cintas2016automatic} can be located on the ear edge or inside the pimas of the ears.

Early methods \cite{lowe2004distinctive,bay2006surf,palaniswamy2010automatic} mainly focused on the low level-vision of the image by applying the image processing techniques, and segmentation is most often the first and the most important step in the process. This task remains a bottleneck to compute the features of the complex image. Even if the interested object is easy to extract, the process may take a bit of time to extract the exciting features. The emergence of deep learning has seen success in other fields of computer vision and key points detection is also not an exception. It has been used to predict the fashion landmarks \cite{liu2016fashion}, human facial key points \cite{sun2013deep,zhang2014facial}, or ear landmarks \cite{cintas2016automatic}.

In this work, we use deep learning, specifically CNN, to predict the landmarks on biological anatomical images. The main idea consists of the designing and training a CNN on a dataset with manual landmarks. Like other CNNs, the features are extracted by using a group of different layer types (i.e. convolutional layer, pooling layer,\ldots) followed by some fully connected layers to provide the prediction of the network. After designing, the proposed model will be trained on the dataset includes the images which are taken from $293$ beetles. For each beetle, the biologists have taken images of five parts: \textit{left and right mandibles, head, elytra, and pronotum} (Fig. \ref{figbeetles}). All the images are presented in the RGB color model with two dimensions. Along with each image, a set of landmarks has been marked by experts which can be used as ground truth to evaluate the predicted landmarks. During the experiments, the proposed network has been trained on the dataset by applying two strategies. In the first strategy, the network is trained from scratch on each dataset; while in the second strategy, the training process has been modified to include a fine-tuning \cite{yosinski2014transferable} stage. Besides, the value of Root Mean Square Error (RMSE) is used to compute the losses during two experiment processes.
